{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "tokenizer_word = lambda x: [y for y in jieba.lcut(x)]  # 以词为单位构建词表(用jieba分词)\n",
    "tokenizer_char = lambda x: [y for y in x]  # 以字为单位构建词表\n",
    "\n",
    "\n",
    "# 句子转标号\n",
    "def str2index(string, tokenizer, vocab):\n",
    "    index = tokenizer(string)\n",
    "    return [vocab.index(idx) if idx in vocab else len(vocab) - 1 for idx in index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ldy\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.484 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 6, 7, 8]\n",
      "[0, 1, 2, 8, 10, 9, 3, 10]\n"
     ]
    }
   ],
   "source": [
    "string = '我今天去你家吃饭'\n",
    "vocab_word = ['我', '今天', '吃', '的', '很', '开心', '去', '你家', '[UKN]']\n",
    "vocab_char = ['我', '今', '天', '吃', '的', '很', '开', '心', '去', '家', '[UKN]']\n",
    "\n",
    "indexByWord = str2index(string, tokenizer_word, vocab_word)\n",
    "indexByChar = str2index(string, tokenizer_char, vocab_char)\n",
    "\n",
    "print(indexByWord)\n",
    "print(indexByChar)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 6821, 3221,  671,  702, 4850,  891, 1368, 2094,  511,  102]])\n",
      "torch.Size([1, 11, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 用预训练的BERT模型进行初始化\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "model = BertModel.from_pretrained('bert-base-chinese')\n",
    "# 输入句子\n",
    "sentence = \"这是一个示例句子。\"\n",
    "# 使用BERT Tokenizer对句子进行编码\n",
    "input_ids = tokenizer.encode(text=sentence)\n",
    "input_ids = torch.LongTensor(input_ids).unsqueeze(0)\n",
    "\n",
    "# 使用BERT模型获取词嵌入\n",
    "with torch.no_grad():\n",
    "    last_hidden_states,cls_states = model(input_ids, return_dict=False)\n",
    "lc = nn.Linear(768, 5)\n",
    "out = lc(cls_states)\n",
    "\n",
    "# print(last_hidden_states)\n",
    "print(input_ids) # tokenizer后的句子张量\n",
    "print(last_hidden_states.shape) # bert输出的句子embedding张量，shape第一维表示句子，第二维表示token，第三维表示token的特征维度\n",
    "print(cls_states.shape) # bert输出的[CLS]的张量，shape第一维表示句子，第二维表示特征维度\n",
    "print(out.shape) # [CLS]张量经过全连接层后的输出，输出每一个label的概率"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}